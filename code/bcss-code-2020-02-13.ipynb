{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UKDS Logo](./images/UKDS_Logos_Col_Grey_300dpi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Being a Computational Social Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the <a href=\"https://ukdataservice.ac.uk/\" target=_blank>UK Data Service</a> training series on *New Forms of Data for Social Science Research*. This series guides you through some of the most common and valuable new sources of data available for social science research: data collected from websites, social media platorms, text data, conducting simulations (agent based modelling), to name a few. We provide webinars, interactive notebooks containing live programming code, reading lists and more.\n",
    "\n",
    "* To access training materials for the entire series: <a href=\"https://github.com/UKDataServiceOpen/new-forms-of-data\" target=_blank>[Training Materials]</a>\n",
    "\n",
    "* To keep up to date with upcoming and past training events: <a href=\"https://ukdataservice.ac.uk/news-and-events/events\" target=_blank>[Events]</a>\n",
    "\n",
    "* To get in contact with feedback, ideas or to seek assistance: <a href=\"https://ukdataservice.ac.uk/help.aspx\" target=_blank>[Help]</a>\n",
    "\n",
    "<a href=\"https://www.research.manchester.ac.uk/portal/julia.kasmire.html\" target=_blank>Dr Julia Kasmire</a> and <a href=\"https://www.research.manchester.ac.uk/portal/diarmuid.mcdonnell.html\" target=_blank>Dr Diarmuid McDonnell</a> <br />\n",
    "UK Data Service  <br />\n",
    "University of Manchester <br />\n",
    "May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Quick-guide\" data-toc-modified-id=\"Quick-guide-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Quick guide</a></span><ul class=\"toc-item\"><li><span><a href=\"#Structure\" data-toc-modified-id=\"Structure-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Structure</a></span></li><li><span><a href=\"#Interaction\" data-toc-modified-id=\"Interaction-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Interaction</a></span></li><li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Table of Contents</a></span></li><li><span><a href=\"#Learn-more\" data-toc-modified-id=\"Learn-more-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Learn more</a></span></li></ul></li><li><span><a href=\"#Why-be-a-Computational-Social-Scientist?\" data-toc-modified-id=\"Why-be-a-Computational-Social-Scientist?-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Why be a Computational Social Scientist?</a></span></li><li><span><a href=\"#How-do-I-be-a-Computational-Social-Scientist?\" data-toc-modified-id=\"How-do-I-be-a-Computational-Social-Scientist?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>How do I be a Computational Social Scientist?</a></span></li><li><span><a href=\"#Big-Five-for-Computational-Social-Science\" data-toc-modified-id=\"Big-Five-for-Computational-Social-Science-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Big Five for Computational Social Science</a></span><ul class=\"toc-item\"><li><span><a href=\"#Thinking-computationally\" data-toc-modified-id=\"Thinking-computationally-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Thinking computationally</a></span></li><li><span><a href=\"#Acquiring-data\" data-toc-modified-id=\"Acquiring-data-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Acquiring data</a></span></li><li><span><a href=\"#Writing-code\" data-toc-modified-id=\"Writing-code-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Writing code</a></span></li><li><span><a href=\"#Knowing-your-computational-environment\" data-toc-modified-id=\"Knowing-your-computational-environment-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Knowing your computational environment</a></span></li><li><span><a href=\"#Understanding-and-manipulating-unstructured/unfamiliar-data\" data-toc-modified-id=\"Understanding-and-manipulating-unstructured/unfamiliar-data-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Understanding and manipulating unstructured/unfamiliar data</a></span></li><li><span><a href=\"#Working-with-data\" data-toc-modified-id=\"Working-with-data-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Working with data</a></span></li><li><span><a href=\"#Documenting-and-enhancing-your-workflow\" data-toc-modified-id=\"Documenting-and-enhancing-your-workflow-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Documenting and enhancing your workflow</a></span></li><li><span><a href=\"#Visualising-data\" data-toc-modified-id=\"Visualising-data-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Visualising data</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span></li><li><span><a href=\"#Bibliography\" data-toc-modified-id=\"Bibliography-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Bibliography</a></span></li><li><span><a href=\"#Further-Reading-and-Resources\" data-toc-modified-id=\"Further-Reading-and-Resources-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Further Reading and Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "* Change all links to `<a>` and `target=blank`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Computational Social Science: it can be a scary, alluring, mystifying term. You may even be thinking, what's the big deal? Surely almost all social science involves the use of computers: we code our interviews using software such as NVivo; build our statistical models in SPSS, Stata etc; and generally conduct our research and teaching activities within a computational environment (e.g., personal desktop/laptop, Dropbox or iCloud for file storage). However, computational social science (CSS) refers to activities and technologies that go beyond what we're typically familiar with as social scientists:\n",
    "* The use of datasets that are too large to store on your personal machine; \n",
    "* Writing programming scripts to access information held in online databases; \n",
    "* Employing analytical techniques, derived from computer science, that reveal structures and patterns in large or unfamiliar datasets (e.g. network analysis, text mining). \n",
    "\n",
    "More formally, CSS is an interdisciplinary branch of research, defined more by its methods and data than its substantive topics (Heiberger & Riebling, 2016). CSS is not limited to certain analytical approaches (e.g., Machine Learning) or data types (e.g., text data). So what makes CSS different from \"traditional\" social science? What are the techniques that are not well suited to familiar statistical software packages such as SAS, SPSS? And why would you want to be a computational social scientist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick guide\n",
    "\n",
    "This is a [Jupyter notebook](https://jupyter.org/), an open-source software application that allows you to mix code, results and narrative in a single document. As [Barba et al. (2019)](https://jupyter4edu.github.io/jupyter-edu-book/) espouse:\n",
    "> In a world where every subject matter can have a data-supported treatment, where computational devices are omnipresent and pervasive, the union of natural language and computation creates compelling communication and learning opportunities.\n",
    "\n",
    "If you are familiar with Jupyter notebooks then skip ahead to the main content. Otherwise, the following is a quick guide to navigating and interacting with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure\n",
    "\n",
    "Notebooks are comprised of cells, of which there are three types:\n",
    "* **Code** - allow you to write executable programming code in multiple languages (default is Python). Each code cell has an output window underneath it for displaying the results the code produces.\n",
    "* **Markdown** - allow you to include narrative content (e.g., paragraphs, headings, images).\n",
    "* **Raw NBConvert** - allow you to write content that is unmodified when the notebook is run (e.g., programming code that is provided as an example and should not be executed).\n",
    "\n",
    "Let's look at examples of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an executable code cell\n",
      "\r\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(\"This is an executable code cell\")\n",
    "print(\"\\r\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(i + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a where we write some narrative about the results the code produces. For example, the code cell above loops through the numbers 0 to 4, adds 10 to each, and displays the result.\n",
    "\n",
    "Markdown is a simple language that takes plain text and renders it in a more visually appealing format, and is primarily used for text published on a web page. For example, you can highlight words using **bold** and *italics*, insert [links](https://en.wikipedia.org/wiki/Markdown), and create lists:\n",
    "1. Item 1\n",
    "2. Item 2\n",
    "    * Sub item 2.1\n",
    "    \n",
    "Double-click on this cell to see the underlying Markdown."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is a raw cell. Its contents are not executed or rendered when we run the cell. For instance the code below will not work in this cell.\n",
    "\n",
    "for i in range(5):\n",
    "    print(i + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction\n",
    "\n",
    "A major advantage of a Jupyter notebook is the ability to edit and execute cells. For a code cell this means running the code to produce some results; for a markdown cell this means writing, editing and formatting the contents; and raw cells can be edited but not executed.\n",
    "\n",
    "* To edit a cell: double-click the cell and type your changes.\n",
    "* To execute a cell: click or double-click the cell and press the Run button on the top toolbar (you can also use the keyboard shortcut Shift + Enter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "There is a table of contents provided at the top of the notebook, but you can also access this menu at any point by clicking the Table of Contents button on the top toolbar (an icon with four horizontal bars, if unsure hover your mouse over the buttons)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more\n",
    "\n",
    "Jupyter notebooks provide rich, flexible features for conducting and documenting your data analysis workflow. To learn more about additional notebook features, we recommend working through some of the <a href=\"https://github.com/darribas/gds19/blob/master/content/labs/lab_00.ipynb\" target=_blank>materials</a> provided by Dani Arribas-Bel at the University of Liverpool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Why be a Computational Social Scientist?\n",
    "\n",
    "The first principles argument for engaging in CSS is as follows: working with new forms of digital data and analytical methods opens up a whole new galaxy of potential research opportunities. That's a rather grand statement but it's true: vast swathes of our social interactions and personal behaviours are conducted online and/or captured digitally. Our use of social media platforms such as Facebook, Twitter and Instagram generates astounding amounts of data, much of which is available from these platforms if you have the right programming skills. Snapshots of our daily lives are routinely captured and aggreagted into large, rich administrative datasets (e.g., our health and social care records, educational achievements). The value of CSS goes beyond these obvious examples: websites can be scraped and marshalled into statistically-usable datasets, documents aggregated into large corpora of text information that can be mined for interesting patterns (e.g., through sentiment analysis). In summary, many new forms of data are only available through computational means (Kitchin, 2014).\n",
    "\n",
    "Halford and Savage (2017) outline further advantages to engaging in CSS, especially from a data perspective:\n",
    "* Utilise techniques for handling and analysing large-scale, unstructured data. \n",
    "* Capture data that is generated in real time and over time.\n",
    "* Access information on new/previously unmeasured activities.\n",
    "* Access information on familiar/currently measured activities at an unprecedented scale, dynamism or complexity.\n",
    "* It's happening whether we (social scientists) like it or not (see also Heiberger & Riebling, 2016); empirical social science in general is having its moment in the sun, in much the same way the social theorists did in the recent past.\n",
    "\n",
    "\n",
    "Last but certainly not least, there's more to CSS than boosting your research standing or productivity. I rather like Sociologist Dr James Allen-Robertson's thoughts on this:\n",
    "\n",
    "> In response to the question of what computational social science has helped me achieve, it may seem obvious to mention the concrete projects, the outputs, the measurable outcomes. However, for me computational social science has achieved something more substantial and enduring — a new way of working, a new way of thinking, and a new kind of enthusiasm for research.<sup>[1]</sup>\n",
    "\n",
    "[1]: https://campus.sagepub.com/blog/james-allen-robertson-css-blog\n",
    "\n",
    "There are limitations with CSS of course, particularly around ethical consent needed to access and use these new forms of data, computational resources and capacity (e.g., hard drive space, memory), and data quality issues (see Halford and Savage, 2017). But one aspect which should not curtail your aims and activities in this space is your ability *to write code* and *manipulate data*. That's not to say that either skill is easy to obtain, on the contrary they require a mode of thinking and intellectual dexterity that you may not have practiced before. However, the crucial thing to remember is this: a little ability goes a long way. You do not need to attain the rank of software engineer to successfully scrape a website, nor invest in your own high-performance computing environment or server to manipulate data accessed through Spotify or Twitter. Brooker (2020) calls this approach the \"grilled cheese\" methodology for programming: your activities just need to be effective i.e., produce the results you need or expect. Elegance, concision and optimisation (e.g., shaving milliseconds off the running time of your code) can come later - or not at all - as a computational social scientist.\n",
    "\n",
    "The good news is the field is sufficiently mature that the code and tools necessary to be a computational social scientist are readily accessible and masterable in a short period of time (think weeks instead of months/years). The aim - in the short-term at least - is not to learn everything about a particular technique, but enough to achieve your research aim e.g., write an executable programming script for collecting data from Wikipedia; Dr James Allen-Robertson again:<sup>[1]</sup>\n",
    "\n",
    "> What mattered here wasn’t necessarily the nuts and bolts of the techniques I was learning, but the development of a 'methodological imagination' and an understanding of the application of these techniques.\n",
    "\n",
    "This may seem unambitious, to grasp the basic concepts and be able to implement foundational techniques, but even this is enough to be able to understand the implications of new forms of data/techniques for your work. Which brings us to our final key point: social science research is increasingly interdisciplinary and knowledge of computational social science techniques puts you in an advantageous position for attracting research funding, securing permanent academic positions etc (Brooker, 2020). My message is clear: embrace this new world with enthusiasm and a critical and reflexive mindset.\n",
    "\n",
    "<!--Material added by JK, needs to be worked in -->\n",
    "<!-- * We live in a world of data (what does that even mean?!?). In fact, we pretty much always have been, although in the pre-digital ages most of that data is probably not what we would consider to be “data” in the way that we understand it now. But it was data nonetheless! As data accumulated, it began to be a problem. How does someone remember it all? How can someone make sure that the right person has new data? How can someone get to the right bit of data at the right time? How best to ensure data is accurate? Fortunately, people developed some pretty good methods for dealing with the problems. These included systems for learning, transferring, testing and accessing data. For example; writing systems allowed data to be transmitted without relying on a specific living messenger being privy to the message, the scientific method allowed insights and discoveries to be replicated ensuring data accuracy, and the dewey decimal system allowed library goers to quickly zoom in on areas that are most likely to have relevant data.  The world of data that surrounds us now includes digital data... Obviously “data-ish” data. And, sensibly, we have developed some methods of dealing with digital data, some based on the data methods developed for non-digital data. Storage drives full of folders with sensible names, for example, are like digital versions of libraries with organised shelves. I am sure you can all imagine more examples.  But, problematically, our modern data world now includes some (very) fast data. Not all of the long-established data methods are well-suited to the fast-moving digital data. For example, the idea that data should be carefully divided into documents, labelled, and stored does not work especially well for data that is continuous, spread over many sources, subject to change, or that is most useful when rapidly accessed.   \n",
    "\n",
    "* Social sciences have traditionally used certain kinds of (slow) data \n",
    "* Social sciences may need to embrace computational thinking in order to use the (very) fast data  -->\n",
    "\n",
    "<!-- What is data and how is it different than information? \n",
    "There is a subtle difference between data and information. Data are the facts or details from which information is derived. Individual pieces of data are rarely useful alone. For data to become information, data needs to be put into context. \n",
    "Data exists, as it were, out there in the world. Information is created, for a purpose, by interpreting data within a given context.  \n",
    "What kind of data are humans good at using? And computers? \n",
    "Humans tend to be good at finding patterns in messy, sparse or irregular data. This is to say, humans are good at deriving information out of minimal data. In theory, this is because we have an evolutionary drive to jump to conclusions as quickly as possible – it is better to flee from the tiger that you think you can hear creeping up behind you than to carry on gathering data about what might be causing the sound of approaching footsteps in the jungle. However, evolution-driven instincts are most applicable to evolutionary problems, so humans tend to be better deriving information efficiently from situations that involve immediate danger, other people, food, and other basic life situations. A good example is how almost all people acquire language in early childhood from the erratic and error-prone output of people around them under often difficult or unusual conditions. This is because language is a clear advantage for a species that reliably exists in a social and communicative context, both in the context of turning the jumble of noise that comes out of people’s mouths into coherent messages and in the context of language acquisition, in which a jumble of noise is turned into a syntax, vocabulary, etc.  \n",
    "Likewise, people are very good at detecting faces, even doing so in tortilla scorch marks or clouds of smoke, even though the detected faces are detected against strange backgrounds, in all lighting conditions, at unpredictable angles and contrary to all expectations. This is because detecting human faces, in a wide range of potentially surprising conditions, is also a clear advantage to a social species like humans. Consequently, humans are very good at picking up on some very subtle and complex patterns in very challenging conditions.  \n",
    "In contrast, humans are not good at reliably and accurately churning through boring and predictable data. Humans get bored, attention wanders, errors are made. In situations were errors have catastrophic consequences, then you really don’t want to rely on a human to be paying attention to a boring stream of data. Computers though, are very good at reliably working with boring data. You want a measurement added to a list once per hour? You want a computer for that!  \n",
    " \n",
    "What problems arise when the differences between human and computer approaches to data are not acknowledged or dealt with? \n",
    "Errors in contexts where errors matter is the biggest problem of asking humans to do computer-things. On the other side, meaningless or counter-productive choices are the result of trusting data when information is actually more valuable.   -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## How do I be a Computational Social Scientist?\n",
    "\n",
    "The good news is, as a trained social scientist, you're most of the way there. Social scientists possess knowledge - theoretical and empirical - of social systems and phenomena, and have advanced data skills, especially around categorising and coding responses (whether qualitative or quantitative), evaluating data quality (e.g., why is this survey response missing?), and making inferences from data (e.g., how representative is this pattern of a larger population?). The gap in your skillset concerns programming and computational proficiency.\n",
    "\n",
    "Though there are myriad aspects to the role, being a computational social scientist typically involves one or more of the following practices:\n",
    "* Writing programming scripts to collect and manipulate data.\n",
    "* Employing analytical techniques - many derived from computer/information sciences - to reveal patterns in data.\n",
    "* Using technological tools and e-Research best practice to structure and document your research workflow.\n",
    "\n",
    "We'll explore many examples of each throughout this [book/training series], but for now we're going to focus on the skills and behaviours that underpin the above activities. Let's call these our *Big Five for CSS*:\n",
    "1. Thinking computationally\n",
    "2. Writing code\n",
    "3. Knowing your computational environment\n",
    "4. Understanding and manipulating data\n",
    "5. Documenting and enhancing your workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Five for Computational Social Science\n",
    "\n",
    "General structure of each section:\n",
    "1. Theory/abstract\n",
    "2. Practical instantiation\n",
    "3. Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking computationally\n",
    "\n",
    "[Barba et al. (2019)](https://jupyter4edu.github.io/jupyter-edu-book/)\n",
    "\n",
    "* Decomposition: Breaking down data, processes, or problems into smaller, manageable parts\n",
    "* Pattern Recognition: Observing patterns, trends, and regularities in data\n",
    "* Abstraction: Identifying the general principles that generate these patterns\n",
    "* Algorithm Design: Developing the step by step instructions for solving this and similar problems\n",
    "\n",
    "### Acquiring data\n",
    "Surveys and e-surveys \n",
    "Official data sources and data requests \n",
    "“found” data \n",
    "Scraped data \n",
    "Repurposed data \n",
    "Other \n",
    "\n",
    "<!-- Another item in the \"Big Five\"? or Just part of thinking computationally? Something to get people out of their normal mindsets of \"How do I answer this research question...?\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing code\n",
    "\n",
    "Perhaps the most crucial aspect of being a computational social scientist, the ability to write code can bring enourmous rewards. _Description/definition of programming and how it is similar to writing syntax for SPSS, Stata etc_\n",
    "\n",
    "Programming can be conceived as a social research method:\n",
    "\n",
    "> as a multipurpose toolkit for understanding and intervening in the (digital) social world in lots of different ways (Brooker, 2019, p.#).<sup>[2]</sup>\n",
    "\n",
    "[2]: https://doi.org/10.1177/0038026119840988\n",
    "\n",
    "This idea of \"Programming-as-Social Science\" carries with it two important distinctions (Brooker, 2019):\n",
    "1. **Coding-as-method** - using code to interact with or probe the social world (e.g. through data collection scripts).\n",
    "2. **Programming-as-analysis** - employing a coding mindset/knowledge of code to conceptualise and research social phenomena differently (e.g. ).\n",
    "\n",
    "Though the objective of any research project is to produce a robust and defensible finding (theoretical or empirical), the manner in which you conduct your activities is increasingly important. This impinges on the code you write, also. There is a school of thought that emphasises the readability and fluency of code, known as _literate programming (LP)_. The father of this approach, Donald Knuth (n.d.), summarises its high level aim:\n",
    "\n",
    "> Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.<sup>[3]</sup>\n",
    "\n",
    "Such a statement probably appears grandoise and abstract, but there are important practical implications of this idea. The coder (or essayist in LP parlance):\n",
    "\n",
    "> chooses the names of variables carefully and explains what each variable means. He or she strives for a program that is comprehensible because its concepts have been introduced in an order that is best for human understanding.\n",
    "\n",
    "Being a literate programmer does not mean writing screeds of comments and headings for the sake of it, far from it (remember: conciseness is paramount). We'll cover this topic in more detail in section 1.3.5 (add anchor).\n",
    "\n",
    "[3]: http://www.literateprogramming.com/knuthweb.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing your computational environment\n",
    "\n",
    "All computational social science activities are dependent on knowing how to setup, manage and share a computational environment. This can be as simple as understanding how and where files are located on your machine, to defining and documenting which software packages, versions and configurations are necessary to execute your data analysis. Whether you are thinking about scraping a web page or implementing an advanced machine learning algorithm, it all begins with establishing your computational environment. First, let's understand how files are stored and accessed on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t95171dm\\projects\\ukds-webinars\\bcss\n"
     ]
    }
   ],
   "source": [
    "!echo %cd%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File system\n",
    "\n",
    "It is critical that you think *logicially* and in an *organised* way about how you manage and store files for your project.\n",
    "\n",
    "Files are stored on your machine's hard drive, and be accessed in two ways:\n",
    "Absolute path\n",
    "Relative path\n",
    "\n",
    "For example, we can ask Python to return the current working directory (i.e., where this notebook is located)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\t95171dm\\\\projects\\\\ukds-webinars\\\\bcss'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list the contents of a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'bcss-code-2020-02-13.ipynb',\n",
       " 'convert-data-structures-2010-03-16.ipynb',\n",
       " 'data',\n",
       " 'images',\n",
       " 'outlines']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir() # return contents of current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oxfam-csv-2020-03-16.csv',\n",
       " 'oxfam-csv-2020-03-16.json',\n",
       " 'oxfam-csv-2020-03-16.xml']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/\") # return contents of the \"data\" directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environments\n",
    "\n",
    "Your computational environment consists of hardware (e.g., the physical machine and its Central Processing Unit) and software (e.g., operating system, programming langauges and their versions, files). For instance, here is a snapshot of my computational environment as of 2020-03-30; first, the operating system:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OS Name:                   Microsoft Windows 10 Enterprise\n",
    "OS Version:                10.0.17763 N/A Build 17763\n",
    "OS Manufacturer:           Microsoft Corporation\n",
    "Original Install Date:     28/02/2020, 16:42:11\n",
    "System Boot Time:          28/02/2020, 16:54:15\n",
    "System Manufacturer:       LENOVO\n",
    "System Model:              20NYS2B800\n",
    "System Type:               x64-based PC\n",
    "Processor(s):              1 Processor(s) Installed.\n",
    "                           Intel64 Family 6 Model 142 Stepping 12 G\n",
    "Total Physical Memory:     16,132 MB\n",
    "Available Physical Memory: 8,349 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And my version of Python, plus some of the additional packages installed:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Python 3.7.3\n",
    "\n",
    "qgrid==1.3.0\n",
    "QtAwesome==0.6.1\n",
    "qtconsole==4.7.1\n",
    "QtPy==1.9.0\n",
    "requests==2.23.0\n",
    "retrying==1.3.3\n",
    "rise==5.6.1\n",
    "rope==0.16.0\n",
    "ruamel-yaml==0.15.87\n",
    "scikit-image==0.16.2\n",
    "scikit-learn==0.22.1\n",
    "scipy==1.4.1\n",
    "seaborn==0.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational environments tend to be unique: for example, you may have different software applications installed on your machine compared to your classmate; or some machines in your computer lab run Windows 10, others Windows 7. This customisability presents considerable challenges for conducting, sharing and reproducing scientific work. In the words of the Turing Institute:<sup>[5]</sup>\n",
    "> The analysis should be *mobile*. Mobility of compute is defined as the ability to define, create, and maintain a workflow locally while remaining confident that the workflow can be executed elsewhere.\n",
    "\n",
    "Trying and failing to reproduce a piece of work after switching to a new machine is, frankly, soul destroying. Thankfully, there are numerous, simple technological solutions for capturing and sharing your computational environment.\n",
    "\n",
    "##### Capturing a computational environment\n",
    "\n",
    "An environment is analogous, in that it acts as a means of _partitioning_ your machine into separate units, each one customised for a certain project. For example, on one of my machines I have two environments: one for collecting charity data for Australia; and another for interacting with the [Companies House API](https://developer.companieshouse.gov.uk/api/docs/). Each environment has Python installed but customised with different Python packages - for example, I do not perform any web-scraping for the Companies House project, therefore I did not install `requests` or `BeautifulSoup` on this environment. The benefit of this approach becomes apparent when you need to use a wide variety of functions/commands in your work and certain packages rely on a specific version of other packages. If you use one environment for multiple pieces of work, your scripts may break as you upgrade packages to newer versions. Running separate environments for different projects allows you to manage these package dependencies carefully and correctly.\n",
    "\n",
    "Interacting with and undertanding your computer at a more fundamental level is also excellent training for running your own server for research (or other) purposes. What is a server? Think of it as a more powerful form of personal computer, running in the cloud, and your primary means of communicating with it is through the Command Line Interface (CLI). It is always on (barring any planned or unplanned downtime) and thus is particularly useful for running automated, scheduled tasks e.g. conducting a weekly scrape of a particular web page.\n",
    "\n",
    "[5]: https://the-turing-way.netlify.com/reproducible_environments/reproducible_environments.html\n",
    "\n",
    "<!-- Material added by JK to be worked in -->\n",
    "<!-- Learning to code (it is not as scary as you think) \n",
    "Why coding is useful \n",
    "What coding languages should you bother with learning \n",
    "But how do you actually “do” the coding \n",
    "More on this  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding and manipulating unstructured/unfamiliar data\n",
    "\n",
    "Data literacy - the ability to manipulate a wide variety of different types of data - is front-and-centre in computational social science. Why do you need computional skills for handling data? Picture the following scenarios:\n",
    "* You've found a website that publishes statistics about a phenomenon of interest, however these are updated daily and you do not have the time to extract the figures, copy them to a new row in a file etc.\n",
    "* You would like to analyse \n",
    "\n",
    "Being data literate involves understanding two key properties of datasets:\n",
    "1. How the contents of the dataset are stored (e.g., as numbers and/or text).\n",
    "2. How the contents of the dataset are structured (e.g., as rows of observations, or networks of relations).\n",
    "\n",
    "#### Data types\n",
    "\n",
    "Data types provide a means of classifying the contents (values) of your dataset. For example, in [Understanding Society](https://www.understandingsociety.ac.uk/) there are questions where the answers are recorded as numbers e.g., [`prfitb`](https://www.understandingsociety.ac.uk/documentation/mainstage/dataset-documentation/variable/prfitb) which captures total personal income; [One more example of qualitative variable]\n",
    "\n",
    "Data types are important as they determine which values can be assigned to them, and what operations can be performed using them e.g., can you calculate the mean value of a piece of text (Tagliaferri, n.d.)?<sup>[4]</sup> Let's cover some of the main data types in Python.\n",
    "\n",
    "[4]: https://assets.digitalocean.com/books/python/how-to-code-in-python.pdf\n",
    "\n",
    "<!-- Material added by JK to be worked in -->  \n",
    "<!-- Structured vs. unstructured (or more accurately, semi-structured) data \n",
    "Fully structured data vs. completely unstructured data \n",
    "Real-world data  \n",
    "Practical matters, or Rows and columns vs. free text \n",
    "\n",
    "\n",
    "<!-- Think hard about data \n",
    "Do you start by thinking about ideal data and then try to acquire the best possible match? \n",
    "Or do you start with what is available and try to find the most useful thing to say about it? \n",
    "Bit of both? What are the limitations? \n",
    " Searching structured data \n",
    "Regular expressions \n",
    "Databases \n",
    "Hierarchies (semantic web, ontologies, etc.) \n",
    "Other? \n",
    "Searching un/semi-structured data \n",
    "Regular expressions again \n",
    "Free text fields \n",
    "Text-mining \n",
    "Machine learning \n",
    "Deep learning \n",
    "Edge-detection \n",
    "AI \n",
    "Other?  -->\n",
    "\n",
    "### Working with data\n",
    "\n",
    "<!-- Ideal or tidy data \n",
    "Cutting and subsetting \n",
    "Joining and merging \n",
    "Recoding values \n",
    "Coding data \n",
    "Other? \n",
    "Combining and cleaning data \n",
    "Combining data with and without a common field \n",
    "Cleaning messy, incomplete, or inconsistent data \n",
    "Embrace the mess – using missing/incomplete/inconsistent data as a source of information  -->\n",
    "<!-- More material added by JK. Will this be another of the \"Big Five\"? Or maybe work into an existing section. But data prep is so important that it seems like it could be a section on its own.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numbers\n",
    "\n",
    "These can be integers or floats (decimals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integers\n",
    "\n",
    "myint = 5\n",
    "yourint = 10\n",
    "print(\"Summing integers: \", myint + yourint)\n",
    "\n",
    "# Floats\n",
    "\n",
    "myflo = 5.5\n",
    "yourflo = 10.7\n",
    "print(\"Summing floats: \", myflo + yourflo)\n",
    "\n",
    "# Combining integers and floats\n",
    "\n",
    "newnum = myint + myflo\n",
    "print(\"Data type when we sum an integer and a float: \", type(newnum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strings\n",
    "\n",
    "This data type stores text information. Strings are immutable in Python i.e., you cannot permanently change its value after creating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings\n",
    "\n",
    "mystring = \"This is my first string.\"\n",
    "print(mystring)\n",
    "\n",
    "yourstring = mystring.replace(\"my\", \"your\") # replace the word \"my\" with \"your\"\n",
    "print(yourstring)\n",
    "\n",
    "splitstring = yourstring.split(\"your\") # split into separate strings\n",
    "print(splitstring)\n",
    "\n",
    "# Add more material from other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating strings will be a common and crucial task during your computational social science work. We'll cover intermediate and advanced string manipulation throughout these training materials but for now we highly suggest you consult the resources listed below.\n",
    "\n",
    "*Further Resources*:\n",
    "* [Principles and Techniques of Data Science](https://www.textbook.ds100.org) - Chapter 8.\n",
    "* [Python 101](https://python101.pythonlibrary.org) - Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boolean\n",
    "\n",
    "This data type captures true or false values (think of dummy/indicator variables that you may have used in Stata, SPSS etc). Boolean data allow us to evaluate expressions or calculations (e.g., is one variable equal to another? Is this word found in a paragraph?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean\n",
    "\n",
    "result = (10+5) == (14+1) # check if two sums are equal\n",
    "print(result) # print the value of the \"result\" object\n",
    "print(type(result)) # print the data type of the \"result\" object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Booleans are also very useful for controlling the flow of your code: in the below example, we assign somebody a grade and then evaluate whether the grade is above a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = 71\n",
    "\n",
    "if grade >= 40:\n",
    "    print(\"Congratulations, you have passed!\")\n",
    "else:\n",
    "    print(\"uh oh, exam resits for you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grade >= 40) # evaluate this expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Further Resources*:\n",
    "* [How To Code in Python](https://assets.digitalocean.com/books/python/how-to-code-in-python.pdf) - Chapter 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lists_\n",
    "\n",
    "The list data type stores an ordered, mutable (i.e., you can change its values) sequence of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list\n",
    "\n",
    "numbers = [1,2,3,4,5]\n",
    "print(numbers)\n",
    "\n",
    "strings = [\"Hello\", \"world\"]\n",
    "print(strings)\n",
    "\n",
    "mixed = [1,2,3,4,5,\"Hello\", \"World\"]\n",
    "print(mixed)\n",
    "\n",
    "mixed = [numbers, strings]\n",
    "print(mixed) # this is a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List length\n",
    "\n",
    "length = len(numbers)\n",
    "print(\"The numbers list has {} items\".format(length)) \n",
    "# the curly braces act as a placeholder for what we reference in .format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing items (elements) within a list\n",
    "\n",
    "print(\"{} is the second item in the list\".format(numbers[1]))\n",
    "# note that the position of items in a list (known as its 'index position')\n",
    "# begins at zero i.e., [0] represents the first item in a list\n",
    "\n",
    "# We can also loop through the items in a list:\n",
    "\n",
    "print(\"\\r\") # add a new line to the output to aid readability\n",
    "for item in numbers:\n",
    "    print(item)\n",
    "# note that the word 'item' in the for loop is not special and\n",
    "# can instead be defined by the user - see below   \n",
    "\n",
    "print(\"\\r\")\n",
    "for chicken in numbers:\n",
    "    print(chicken)\n",
    "# of course, such a silly name does nothing to aid interpretability of the code    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding or removing items in a list\n",
    "\n",
    "numbers.append(6) # add the number six to the end of the list\n",
    "print(numbers)\n",
    "\n",
    "numbers.remove(3) # remove the number three from the list\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Dictionaries_\n",
    "\n",
    "The dictionary data type maps keys (i.e., variables) to values; thus, data in a dictionary are stored in key-value pairs (known as items). Dictionaries are useful for storing data that are related e.g., variables and their values for an observation in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary\n",
    "\n",
    "dict = {\"name\": \"Diarmuid\", \"age\": 32, \"occupation\": \"Researcher\"}\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing items in a dictionary\n",
    "\n",
    "print(dict[\"name\"]) # print the value of the \"name\" key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict.keys()) # print the dictionary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict.items()) # print the key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining with lists\n",
    "\n",
    "obs = [] # create a blank list\n",
    "\n",
    "ind_1 = dict # create dictionaries for three individuals\n",
    "ind_2 = {\"name\": \"Jeremy\", \"age\": 50, \"occupation\": \"Nurse\"}\n",
    "ind_3 = {\"name\": \"Sandra\", \"age\": 41, \"occupation\": \"Chef\"}\n",
    "\n",
    "for ind in ind_1, ind_2, ind_3: # for each dictionary, add to the blank list\n",
    "    obs.append(ind)\n",
    "\n",
    "print(obs)# print the list\n",
    "print(\"\\r\")\n",
    "print(type(obs)) # now we have a list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Social science applications_\n",
    "\n",
    "You may be wondering how the above examples have social science applications. To answer, here is an example from my research. Let's say I want to scrape First, I want to define a list of charity numbers that I "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data structures\n",
    "\n",
    "Indulge me: close your eyes and visualise a dataset. What do you picture? Heiberger and Riebling (2016, p. 4) are confident they can predict what you visualise:\n",
    "\n",
    "> Ask any social scientist to visualize data; chances are they will picture a rectangular table consisting of observations along the rows and variables as columns.\n",
    "\n",
    "This dataset (also known as a variable-by-case matrix or data frame) is a type of data structure: it stores values (e.g., text or numbers) in variables (e.g., strings or integers) in rows for _n_ number of observations. [Comment on why this is not always the best structure e.g. network data] As you engage in computational social science, you will encounter many more types of data structure, some of which may be unfamiliar; for now let's focus on some of the more common ones. We'll use some sample data - organisational and financial information for the charity [Oxfam](https://beta.charitycommission.gov.uk/charity-details/?regId=202918&subId=0) - to demonstrate and compare the properties of each data structure.\n",
    "\n",
    "##### Data frame\n",
    "\n",
    "A data frame is a rectangular data structure and is often stored in a Comma-Separated Value (CSV) file format. A CSV stores observations in rows, and separates (or \"delimits\") each value in an observation using a comma (','). Let's examine a CSV dataset in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # module for handling CSV files\n",
    "\n",
    "with open(\"./data/oxfam-csv-2020-03-16.csv\", \"r\") as f: # open file in 'read mode' and store in a Python CSV object called 'reader'\n",
    "    reader = csv.reader(f) # read data in file\n",
    "    for row in reader: # for every row in the data, print the contents of the row\n",
    "        print(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though not as readable as we would like (compared to opening the file in Excel, Stata etc), we can clearly identify the structure of this file:\n",
    "* the first row contains the variables;\n",
    "* the following rows contain values for those variables, separated by commas; and\n",
    "* each row is clearly defined as beginning on a new line\n",
    "\n",
    "There is another way of opening CSV files and handling their contents: using the `pandas` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # module for handling data frames\n",
    "\n",
    "df = pd.read_csv(\"./data/oxfam-csv-2020-03-16.csv\") # open the file and store its contents in the \"df\" object\n",
    "df # view the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to work with CSV files is a fairly simple but crucial skill as a computational social scientist: many open-source datasets are shared in this format, and transforming more complicated data structures to CSV files can aid your data analysis workflow (e.g. importing the subsequent CSV file into Stata or R).\n",
    "\n",
    "Now let's look at the same information but stored in a different data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dictionaries\n",
    "\n",
    "A dictionary is a hierarchical data structure based on key-value pairs. Dictionaries are often stored as Javascript Object Notation (JSON) files. Let's examine a JSON dataset in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # import Python module for handling JSON files\n",
    "\n",
    "with open('./data/oxfam-csv-2020-03-16.json', 'r') as f: # open file in 'read mode' and store in a Python JSON object called 'data'\n",
    "    data = json.load(f)\n",
    "          \n",
    "data # view the contents of the JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, readability is not great (see appendix A for other ways of viewing the contents of a JSON file) but we can pick out the core properties of the data structure:\n",
    "* A dictionary begins with '{' and ends with '}';\n",
    "* It can contain nested dictionaries - for example, the value of the first key ('name') is itself a dictionary containing ten key-value pairs (e.g. '0': '01/05/2008 00:00'); and\n",
    "* key-value pairs are separated by a comma (',').\n",
    "\n",
    "Let's dig into some of these properties in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys() # view the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values() # view the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.items() # view the key-value pairs (items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fye']['9'] \n",
    "# view the value of the '9' subkey under the 'fye' key i.e. the tenth value for the financial year end key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XML\n",
    "\n",
    "(EXtensible Markup Language (XML) is a hierarchical data structure (known as a document) that uses tags to identify (or 'markup') the different types of information it contains; XML is also a file format (.xml) used to store XML documents<sup>[4]</sup>. Let's examine an XML dataset in Python:\n",
    "\n",
    "\n",
    "\n",
    "[4]: https://www.w3schools.com/xml/xml_whatis.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify # import Python module for handling XML files\n",
    "\n",
    "xml = objectify.parse(open('./data/oxfam-csv-2020-03-16.xml'))\n",
    "\n",
    "root = xml.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphs\n",
    "\n",
    "[Example of graph data structure e.g., an edge list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are feeling flustered about having to master new data structures, then don't: converting from one structure to another is perfectly fine and common. For example, in my research I often convert dictonaries to data frames and save these as CSV files (see chapter 3). For now it is important that you familiarise yourself with the above structures, as much of the data available via the web is stored in these structures and file formats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documenting and enhancing your workflow\n",
    "\n",
    "There is a growing movement across the scientific community for greater transparency and reproducibility of research. Put simply, \"Reproducible research is necessary to ensure that scientific work can be trusted.\"<sup>[5]</sup>\n",
    "\n",
    "Reproducibility can be summarised as the availability of data and code to fully rerun an analysis. The Turing Way provides a delineation of the various connotations of reproducibility and related terms:\n",
    "* **Reproducible**: A result is reproducible when the same analysis steps performed on the same dataset consistently produces the same answer.\n",
    "* **Replicable**: A result is replicable when the same analysis performed on different datasets produces qualitatively similar answers.\n",
    "* **Robust**: A result is robust when the same dataset is subjected to different analysis workflows to answer the same research question (for example one pipeline written in R and another written in Python) and a qualitatively similar or identical answer is produced. Robust results show that the work is not dependent on the specificities of the programming language chosen to perform the analysis.\n",
    "* **Generalisable**: Combining replicable and robust findings allow us to form generalisable results. Note that running an analysis on a different software implementation and with a different dataset does not provide generalised results. There will be many more steps to know how well the work applies to all the different aspects of the research question. Generalised is an important step towards understanding that the result is not dependent on a particular dataset nor a particular version of the analysis pipeline.\n",
    "\n",
    "\n",
    "Professor Vernon Gayle of the University of Edinburgh has distilled reproducibility best practices into the following guidance (or rules) for social science research:\n",
    "1. Tell us about your software.\n",
    "2. Tells us about your data.\n",
    "3. Show us how you got your data ready.\n",
    "4. Show us all the analysis you did.\n",
    "5. Save all of this work openly.\n",
    "\n",
    "\n",
    "*Further Resources:*\n",
    "* [The Turing Way](https://the-turing-way.netlify.com) - Chapter 2.\n",
    "* [New Rules of the Sociological Method](https://github.com/vernongayle/new_rules_of_the_sociological_method/blob/master/noobs.ipynb).\n",
    "\n",
    "What is the relation between CSS and reproducible research. Well, the former provides a suite of tools and best practices for achieving the latter. Let's run through some of these quickly:\n",
    "* **Jupyter Notebooks**: the materials you are working through were written in a Jupyter notebook, a software application that enables you to interleave live code, results and narrative in a single file. Traditionally, social scientists save their data cleaning and analysis work in one or more files (e.g., Stata DO files), and write up the results in another file (e.g., a MS Word or Latex file). Jupyter notebooks re-establish the connection between conducting and reporting research activities. As [Barba et al. (2019)](https://jupyter4edu.github.io/jupyter-edu-book/) espouse:\n",
    "> In a world where every subject matter can have a data-supported treatment, where computational devices are omnipresent and pervasive, the union of natural language and computation creates compelling communication and learning opportunities.\n",
    "\n",
    "* Github: \n",
    "\n",
    "[J. Scott Long's Workflow of Data Analysis Using Stata]\n",
    "\n",
    "[FAIR principles]\n",
    "\n",
    "[Citing data]\n",
    "    \n",
    "[5]: https://the-turing-way.netlify.com/introduction/introduction.html\n",
    "\n",
    "The most powerful aspect of the technologies outlined above is that they **integrate** with each other. For example, you can conduct and document your analysis in a Jupyter notebook, save it publicly in a Github repostitory, and then use mybinder.org to allow others to reproduce your analysis using only their web browser.\n",
    "\n",
    "<!-- More material added by JK. Just notes, really. -->\n",
    "<!-- Citing sources \n",
    "Collaborative work and version control \n",
    "Replication. Replication. Replication. \n",
    "Sharing data  -->\n",
    "\n",
    "### Visualising data\n",
    "<!-- Another ofthe \"Big Five\"?  -->\n",
    "<!-- Visualising data \n",
    "Why size (and scale) matters \n",
    "Different graphs for different pfaffs \n",
    "Discrete vs. continuous \n",
    "Consider the colour-blind \n",
    "Interactive \n",
    "Dance, sculpture and other visualisations \n",
    "Audio-isations?   -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/a5i42lSj-L4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Hopefully this chapter has demystified aspects of CSS and whetted your appetite for some applied work. The subsequent chapters provide plenty of opportunity to practice CSS with various forms of data. For now I wanted to reflect on some outstanding issues.\n",
    "\n",
    "#### Python vs R vs Julia vs ....\n",
    "\n",
    "[Perhaps a table with some properties of each?] The general point is it's your choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "Brooker, P. (2020). Programming in Python for Social Scientists. LOCATION: PUBLISHER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading and Resources\n",
    "\n",
    "[Copy AQMEN reading lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
